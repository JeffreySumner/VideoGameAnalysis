---
title: "Video Game Demo"
format: html
editor: visual
---

We will be examining data from a Tidy Tuesday repository. The repository can be accessed from the following link: https://github.com/rfordatascience/tidytuesday/tree/master/data/2021/2021-03-16. This dataset contains a time series of video games and their average number of players, peak players and gain in players over time.

With this data, let's see if there are any interesting trends. What does gametime look like over time. Are there any particular games that show interesting statistics? Are there any trends that could be explained based upon the data? Let's find out.

```{r R_setup}
library(reticulate)
use_virtualenv("cse6040")

```

Let's first begin by reading in our data with the code below. The data can be read directly from the rfordatascience Github repo or downloaded then read in.

```{python read_data}
import pandas as pd
import tkinter
import matplotlib.pyplot as plt
video_game_tbl = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-16/games.csv')
```

Now that we have our data, let's examine different characteristics of the data. Below are three different ways to view the data.

Method 1 uses the head() method. This will display the first few rows of data. This is almost identical to the R head function.

```{python}
print(video_game_tbl.head())
```

Next is the iloc() method from pandas. It behaves similar to the head method but slices based on index of either row or column. We will examine the first 5 rows with the code below.

```{python}
print(video_game_tbl.iloc[:5,])

```

Finally, if you are an R user, you will appreciate the info() method. This method is very similar to the glimpse() function found within R's tidyverse suite of packages. The info method will come in handy to quickly see columns and types.

```{python}
video_game_tbl.info()
```

So we can see that we have game information by year and month. Below is a more detailed breakdown of each field from the github repository.

| variable      | class     | description                                                               |
|---------------|---------------|------------------------------------------|
| gamename      | character | Name of video games                                                       |
| year          | double    | Year of measure                                                           |
| month         | character | Month of measure                                                          |
| avg           | double    | Avg. \# of players at the same time                                       |
| gain          | double    | Gain (or loss) difference in avg compared to prior month (NA = 1st month) |
| peak          | double    | Highest \# of players at the same time                                    |
| avg_peak_perc | character | Share of the average in the maximum value (avg/peak) in %                 |

Now that we understand a little more about our structure, let's go ahead and examine any potential missing data within our data. Below we will use isnull() and sum() to figure this out.

```{python}

video_game_tbl.isnull().sum()
```

It looks like we do have some missing values, all from the gain column. If we look back at our data overview, we will see that there are going to be NA's within this column for the first month in the data because it is calculate a percentage increase/decrease.

Let's examine the data a little more to see if there are any NA values that need to be cleaned up. If I were to be doing this in my job, I would check to see if there are 1258 unique games. If there are, then that would explain all of the gain missing values, otherwise there may be duplicate names or some actual missing data! Let's implement this below.

```{python}
video_game_tbl['gamename'].nunique()
```

Voila! There are 1258 unique games in our dataset. This absolutely would explain the missing values in gain.

In all likelihood, we will not need to worry about the first month of each game. Let's go ahead and remove those missing values so they do not become pesky down the road.

```{python}
video_game_clean_tbl = video_game_tbl.dropna()
```

Let's go ahead and confirm that we removed a total of 1258 rows and nothing more.

```{python}
video_game_tbl.shape[0] - video_game_clean_tbl.shape[0] 
```

Let's take a quick look at what years are covered in our data with the code below.

```{python}
video_game_clean_tbl['year'].unique()
```

Cool, we have data going back from 2012 up through 2021. This means we have data through a portion of the pandemic. Let's move on and examine a few games but we will come back to the pandemic call-out.

First let's get the total number of players regardless of time or game.

```{python}
video_game_clean_tbl['avg'].sum()
```

Holy moly. The total averaged value is 226 million. Could you imagine what this number looks like overall? That is a lot of screen-time!

Let's make a visual of this total via a bar graph.

```{python}
fig, bp = plt.subplots()
bp.bar(['Total Gametime'], video_game_clean_tbl['avg'].sum(), color = 'lightblue')
bp.ticklabel_format(axis='y', style='plain')
plt.show()
```

This visual is just a simple way to show off our total. It isn't completely meaningful but now let's view the data by year. First we will group the data by year and store it.

```{python}
video_game_grp_year_tbl = video_game_clean_tbl.groupby('year').agg({'avg' : 'sum'})
video_game_grp_year_tbl
```

Now that we have our data by year, let's visualize it in a bar plot.

```{python}
plt.close()
fig, bp = plt.subplots(1, 1)
bp.bar(video_game_grp_year_tbl.index, video_game_grp_year_tbl['avg'], color = 'lightblue')
bp.ticklabel_format(axis='y', style='plain')

plt.show()
```

Wow something very interesting happened. Each year from 2012-2018 there was an increase in the average but in 2019 we saw our first decline. 2020 immediately saw a rebound! So to break this down, people were able to spend a lot more free-time at home and on video games during 2020 because of the pandemic. What is even more interesting is that 2019 declined! What would have caused that? Was steam running out of steam? Pun fully intended. We may never know. My guess is that during this time there was a lot of additional competition really starting to take off to pull gamers from steam to a different platform. EPIC games store was really starting to hit a groove and things like GOG really took off. This could explain the decline and COVID really explains the sudden up-tick.

Let's go ahead and compare the time spent on games for the year 2020, when we had that huge uptick. We will examine this data by month in the code below.

```{python}

video_game_2020_tbl = video_game_clean_tbl[video_game_clean_tbl['year'] == 2020].groupby('month').agg({'avg' : 'sum'})

plt.close()
fig, bp = plt.subplots(1, 1)
bp.bar(video_game_2020_tbl.index, video_game_2020_tbl['avg'], color = 'lightblue')
bp.ticklabel_format(axis='y', style='plain')

plt.show()
```

Okay, cool we have the graph by month but let's address the elephant in the room... the months are out of order. Great... Let's go ahead and fix that with the code below.

```{python}
month_dict = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,
              'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}
video_game_2020_tbl = video_game_clean_tbl.copy()
video_game_2020_tbl['month_num'] = video_game_2020_tbl['month'].map(month_dict)

video_game_2020_tbl = video_game_2020_tbl[video_game_2020_tbl['year'] == 2020].groupby('month_num').agg({'avg' : 'sum'})
video_game_2020_tbl
```

Now that we have the month number instead of a character, let's go ahead and re-plot!

```{python}
plt.close()
fig, bp = plt.subplots(1, 1)
bp.bar(video_game_2020_tbl.index, video_game_2020_tbl['avg'], color = 'lightblue')
bp.ticklabel_format(axis='y', style='plain')

plt.show()
```

Wow! What we see here is that March, April and May are some of our highest months of the year in terms of avg. Let's see what happens when we examine a different year. Let's look at 2018 when the total was near 2020. Do you think we will see the same trend?

```{python}
month_dict = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,
              'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}
video_game_2018_tbl = video_game_clean_tbl.copy()
video_game_2018_tbl['month_num'] = video_game_2018_tbl['month'].map(month_dict)

video_game_2018_tbl = video_game_2018_tbl[video_game_2018_tbl['year'] == 2018].groupby('month_num').agg({'avg' : 'sum'})

plt.close()
fig, bp = plt.subplots(1, 1)
bp.bar(video_game_2018_tbl.index, video_game_2018_tbl['avg'], color = 'lightblue')
bp.ticklabel_format(axis='y', style='plain')

plt.show()
```

March and April are still very solid months but you can see a totally different trend throughout the year. January and February seemed to be some of the best performing months but were the worst performers compared to 2020. Maybe COVID starting in March of 2020 influenced the entire year after February?
